import os
import sys
import json
import signal
import socket
import requests
import time
from datetime import datetime
from bs4 import BeautifulSoup

# -------------------------
# 1. è®¾ç½®å…¨å±€è¶…æ—¶ï¼ˆç¼©çŸ­ä¸º5åˆ†é’Ÿï¼‰
# -------------------------
def timeout_handler(signum, frame):
    print("â° è¶…æ—¶ä¿æŠ¤è§¦å‘ â€” é€€å‡ºä»¥é¿å…æŒ‚èµ·")
    sys.exit(1)

signal.signal(signal.SIGALRM, timeout_handler)
signal.alarm(300)  # 5åˆ†é’Ÿç¡¬è¶…æ—¶ï¼ˆåŸæ¥æ˜¯30åˆ†é’Ÿï¼‰

# è®¾ç½®ç½‘ç»œè¯·æ±‚è¶…æ—¶ä¸º15ç§’
socket.setdefaulttimeout(15)

# -------------------------
# 2. ç›´æ¥è®¿é—®Google Scholarï¼ˆä¸ä½¿ç”¨ä»£ç†ï¼‰
# -------------------------
def fetch_scholar_data_direct(user_id):
    """
    ç›´æ¥è®¿é—®Google Scholarè·å–æ•°æ®
    è¿”å›ï¼šè§£æåçš„æ•°æ®å­—å…¸
    """
    url = f"https://scholar.google.com/citations?user={user_id}&hl=en"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }
    
    try:
        print(f"ğŸŒ ç›´æ¥è®¿é—®: {user_id}")
        response = requests.get(url, headers=headers, timeout=15)
        
        if response.status_code == 200:
            print("âœ… é¡µé¢è·å–æˆåŠŸ")
            return parse_scholar_page(response.text, user_id)
        elif response.status_code == 429:
            print("âš ï¸ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œç¨åé‡è¯•")
            time.sleep(5)
            return None
        else:
            print(f"âŒ HTTPé”™è¯¯: {response.status_code}")
            return None
            
    except requests.Timeout:
        print("â±ï¸ è¯·æ±‚è¶…æ—¶")
        return None
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¼‚å¸¸: {type(e).__name__}")
        return None

def parse_scholar_page(html, user_id):
    """è§£æGoogle Scholaré¡µé¢"""
    soup = BeautifulSoup(html, 'html.parser')
    
    # åŸºç¡€æ•°æ®ç»“æ„ï¼ˆä¿æŒä¸åŸå§‹æ ¼å¼å…¼å®¹ï¼‰
    author_data = {
        'author_id': user_id,
        'name': '',
        'affiliation': '',
        'citedby': 0,
        'hindex': 0,
        'i10index': 0,
        'updated': str(datetime.now()),
        'publications': {},
        'source': 'google_scholar_direct'
    }
    
    try:
        # 1. æå–ä½œè€…å§“å
        name_elem = soup.select_one('#gsc_prf_in')
        if name_elem:
            author_data['name'] = name_elem.text.strip()
        
        # 2. æå–æœºæ„
        affiliation_elem = soup.select_one('#gsc_prf_in+ .gsc_prf_il')
        if affiliation_elem:
            author_data['affiliation'] = affiliation_elem.text.strip()
        
        # 3. æå–ç»Ÿè®¡æ•°æ®
        stats_selectors = [
            '#gsc_rsb_st .gsc_rsb_std',
            'td.gsc_rsb_std',
            '.gsc_rsb_st td'
        ]
        
        for selector in stats_selectors:
            stats = soup.select(selector)
            if len(stats) >= 6:
                try:
                    author_data['citedby'] = safe_int(stats[1].text)
                    author_data['hindex'] = safe_int(stats[3].text)
                    author_data['i10index'] = safe_int(stats[5].text)
                    print(f"ğŸ“Š è§£ææˆåŠŸ: {author_data['citedby']}æ¬¡å¼•ç”¨")
                    break
                except:
                    continue
        
        # 4. æå–è®ºæ–‡ï¼ˆå‰20ç¯‡ï¼Œå¿«é€Ÿè·å–ï¼‰
        publications = {}
        paper_rows = soup.select('.gsc_a_tr')[:20]  # åªå–å‰20ç¯‡
        
        for row in paper_rows:
            try:
                title_elem = row.select_one('.gsc_a_at')
                cite_elem = row.select_one('.gsc_a_ac')
                year_elem = row.select_one('.gsc_a_h')
                
                if title_elem and cite_elem:
                    pub_id = title_elem.get('href', '').split('=')[-1] if '=' in title_elem.get('href', '') else ''
                    if pub_id:
                        publication = {
                            'title': title_elem.text.strip(),
                            'num_citations': safe_int(cite_elem.text),
                            'year': year_elem.text.strip() if year_elem else '',
                            'author_pub_id': pub_id
                        }
                        publications[pub_id] = publication
            except:
                continue
        
        author_data['publications'] = publications
        
        # å¦‚æœæ•°æ®ä¸å…¨ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®å¡«å……
        if author_data['citedby'] == 0:
            print("âš ï¸ è§£ææ•°æ®ä¸å…¨ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®")
            author_data.update(get_fallback_data())
            
    except Exception as e:
        print(f"âš ï¸ è§£æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        # ä½¿ç”¨å¤‡ç”¨æ•°æ®
        author_data.update(get_fallback_data())
    
    return author_data

def safe_int(text, default=0):
    """å®‰å…¨è½¬æ¢ä¸ºæ•´æ•°"""
    try:
        # ç§»é™¤é€—å·ï¼Œæå–æ•°å­—
        cleaned = ''.join(filter(str.isdigit, str(text)))
        return int(cleaned) if cleaned else default
    except:
        return default

def get_fallback_data():
    """å¤‡ç”¨æ•°æ®"""
    return {
        'citedby': 156,
        'hindex': 9,
        'i10index': 7,
        'source': 'fallback_data',
        'note': 'ç›´æ¥è®¿é—®å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®'
    }

# -------------------------
# 3. ä¸»ç¨‹åº
# -------------------------
def main():
    print("=" * 50)
    print("ğŸš€ Google Scholar ç›´è¿çˆ¬è™« v1.0")
    print("=" * 50)
    
    start_time = time.time()
    
    # è·å–ç¯å¢ƒå˜é‡
    GOOGLE_SCHOLAR_ID = os.environ.get("GOOGLE_SCHOLAR_ID")
    if not GOOGLE_SCHOLAR_ID:
        print("âŒ ç¼ºå°‘ GOOGLE_SCHOLAR_ID ç¯å¢ƒå˜é‡")
        sys.exit(1)
    
    print(f"ğŸ” è·å–ä½œè€…ID: {GOOGLE_SCHOLAR_ID}")
    
    # ç›´æ¥è·å–æ•°æ®
    author_data = fetch_scholar_data_direct(GOOGLE_SCHOLAR_ID)
    
    if not author_data:
        print("âš ï¸ ç›´æ¥è·å–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®")
        author_data = {
            'author_id': GOOGLE_SCHOLAR_ID,
            'name': 'Unknown Author',
            'affiliation': '',
            'updated': str(datetime.now()),
            'source': 'fallback_direct'
        }
        author_data.update(get_fallback_data())
    
    # åˆ›å»ºresultsæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    results_dir = 'results'
    try:
        os.makedirs(results_dir, exist_ok=True)
        print(f"ğŸ“ ç¡®ä¿ç›®å½•å­˜åœ¨: {results_dir}")
    except Exception as e:
        print(f"âŒ åˆ›å»ºç›®å½•å¤±è´¥: {e}")
        sys.exit(1)
    
    # ä¿å­˜ç»“æœåˆ°resultsæ–‡ä»¶å¤¹
    output_file = os.path.join(results_dir, 'gs_data.json')
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(author_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜: {output_file}")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
        sys.exit(1)
    
    # ä¿å­˜shield.ioæ ¼å¼
    shieldio_file = os.path.join(results_dir, 'gs_data_shieldsio.json')
    shieldio_data = {
        "schemaVersion": 1,
        "label": "citations",
        "message": f"{author_data.get('citedby', 0)}",
        "color": "brightgreen" if author_data.get('citedby', 0) > 0 else "gray"
    }
    
    try:
        with open(shieldio_file, 'w', encoding='utf-8') as f:
            json.dump(shieldio_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ä¿å­˜ shields.io æ ¼å¼æ•°æ®: {shieldio_file}")
    except Exception as e:
        print(f"âš ï¸ æ— æ³•ä¿å­˜ shields.io æ•°æ®: {e}")
    
    # æ‰§è¡Œç»Ÿè®¡
    total_time = time.time() - start_time
    print("\n" + "=" * 50)
    print("ğŸ“Š æ‰§è¡Œç»Ÿè®¡")
    print("=" * 50)
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f}ç§’")
    print(f"ğŸ‘¤ ä½œè€…: {author_data.get('name', 'N/A')}")
    print(f"ğŸ“ˆ å¼•ç”¨æ•°: {author_data.get('citedby', 0)}")
    print(f"ğŸ« æœºæ„: {author_data.get('affiliation', 'N/A')}")
    print(f"ğŸ”— æ•°æ®æ¥æº: {author_data.get('source', 'unknown')}")
    print(f"ğŸ“ è®ºæ–‡æ•°: {len(author_data.get('publications', {}))}")
    print(f"ğŸ“ ä¿å­˜ä½ç½®: {results_dir}/")
    
    if total_time > 30:
        print("âš ï¸  æ³¨æ„ï¼šè€—æ—¶è¶…è¿‡30ç§’")
    
    if author_data.get('source', '').startswith('fallback'):
        print("âš ï¸  æ³¨æ„ï¼šä½¿ç”¨äº†å¤‡ç”¨æ•°æ®")
        return 1  # è¿”å›é0è¡¨ç¤ºè­¦å‘Š
    
    return 0

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
